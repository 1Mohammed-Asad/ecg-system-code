#!/usr/bin/env python3
"""
ECG Scanner Device System
Integrated system for scanning paper ECGs and analyzing digital signals
Optimized for emergency cardiac condition detection and actionable recommendations
"""

import sys
import time
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import threading
import queue

# Core libraries
import numpy as np
import cv2
from PIL import Image, ImageEnhance
import matplotlib.pyplot as plt
from scipy import signal, ndimage
from skimage import filters, morphology, measure
import pandas as pd

# Deep Learning
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Conv1D, Conv2D, BatchNormalization, Bidirectional, LSTM, Dense, 
    Dropout, GlobalAveragePooling2D, Input, Concatenate, MaxPooling2D,
    Flatten, Reshape, TimeDistributed
)
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Medical signal processing
import heartpy as hp
import neurokit2 as nk
import wfdb

# Image processing and OCR
import pytesseract
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# Hardware interface (simulated)
try:
    import serial
    import pyserial
    HARDWARE_AVAILABLE = True
except ImportError:
    HARDWARE_AVAILABLE = False
    print("Hardware interface libraries not available - using simulation mode")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ecg_scanner.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ECGImageProcessor:
    """
    Advanced ECG paper image processing using computer vision
    """
    
    def __init__(self):
        # Initialize TrOCR processor and model for OCR tasks.
        # These are used for extracting text (e.g., patient info, device settings) from ECG images.
        self.processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-printed")
        self.model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-printed")
        
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        Enhanced preprocessing for ECG paper images.
        Steps include grayscale conversion, contrast enhancement, noise reduction,
        skew correction, and normalization.
        """
        # Load image from the specified path.
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        # Convert the image to grayscale for simpler processing.
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) for contrast enhancement.
        # This helps in making grid lines and ECG traces more visible.
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # Apply Non-local Means Denoising to reduce noise while preserving edges.
        denoised = cv2.fastNlMeansDenoising(enhanced)
        
        # Correct any skew detected in the scanned image using Hough Lines.
        corrected = self._correct_skew(denoised)
        
        # Normalize pixel values to the full 0-255 range.
        normalized = cv2.normalize(corrected, None, 0, 255, cv2.NORM_MINMAX)
        
        return normalized
    
    def _correct_skew(self, image: np.ndarray) -> np.ndarray:
        """
        Corrects skew in scanned ECG papers by detecting lines and rotating the image.
        """
        # Apply Canny edge detection to find edges in the image.
        edges = cv2.Canny(image, 50, 150, apertureSize=3)
        # Use Hough Line Transform to detect straight lines in the edge map.
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
        
        if lines is not None:
            angles = []
            # Iterate through detected lines (limit to first 10 for performance).
            for rho, theta in lines[:10]:
                # Calculate angle in degrees relative to the horizontal.
                angle = np.degrees(theta) - 90
                angles.append(angle)
            
            if angles:
                # Use median angle to reduce outlier influence.
                median_angle = np.median(angles)
                # Only rotate if the skew is significant (abs value greater than 0.5 degrees).
                if abs(median_angle) > 0.5:
                    rows, cols = image.shape
                    # Get the rotation matrix.
                    M = cv2.getRotationMatrix2D((cols/2, rows/2), median_angle, 1)
                    # Apply the affine transformation to rotate the image.
                    image = cv2.warpAffine(image, M, (cols, rows), 
                                         flags=cv2.INTER_CUBIC, 
                                         borderMode=cv2.BORDER_REPLICATE)
        
        return image
    
    def extract_ecg_grid(self, image: np.ndarray) -> List[np.ndarray]:
        """
        Extracts ECG waveform data by detecting and removing the grid lines from the paper.
        """
        # Define kernels for detecting horizontal and vertical lines.
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        
        # Apply morphological operations to detect horizontal and vertical grid lines.
        horizontal_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, horizontal_kernel)
        vertical_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, vertical_kernel)
        # Combine detected lines to form the complete grid.
        grid = cv2.add(horizontal_lines, vertical_lines)
        
        # Subtract the detected grid from the original image to isolate the ECG signal.
        ecg_signal = cv2.subtract(image, grid)
        
        # Apply closing operation to enhance the signal (fill small gaps).
        ecg_signal = cv2.morphologyEx(ecg_signal, cv2.MORPH_CLOSE, 
                                     cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))
        
        # Segment the image into individual ECG leads.
        leads = self._segment_leads(ecg_signal)
        
        return leads
    
    def _segment_leads(self, image: np.ndarray) -> List[np.ndarray]:
        """
        Segments individual ECG leads from a processed ECG image based on a standard 12-lead layout.
        """
        height, width = image.shape
        
        leads = []
        
        # Standard 12-lead ECG layout typically involves 3 rows of 2 leads each,
        # followed by a long rhythm strip at the bottom.
        # This implementation assumes this common layout.
        
        # Segment top 3 rows (Leads I, II, III, aVR, aVL, aVF)
        # Each row is split into two leads.
        for row in range(3):
            y_start = int(row * height / 4)
            y_end = int((row + 1) * height / 4)
            
            for col in range(2):
                x_start = int(col * width / 2)
                x_end = int((col + 1) * width / 2)
                
                lead_image = image[y_start:y_end, x_start:x_end]
                leads.append(lead_image)
        
        # Segment the bottom rhythm strip (usually Lead II Long or similar).
        rhythm_strip = image[int(3 * height / 4):, :]
        leads.append(rhythm_strip)
        
        return leads
    
    def digitize_ecg_signal(self, lead_image: np.ndarray, 
                           sampling_rate: int = 500) -> np.ndarray:
        """
        Converts a single ECG lead image into a digital signal (time-series data).
        """
        # Apply Otsu's thresholding to convert the grayscale image to a binary image.
        # This separates the ECG trace from the background.
        _, binary = cv2.threshold(lead_image, 0, 255, 
                                 cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Find contours in the binary image. Contours represent the ECG trace.
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, 
                                      cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return np.array([])
        
        # Select the largest contour, assuming it represents the main ECG trace.
        main_contour = max(contours, key=cv2.contourArea)
        
        # Extract y-coordinates for each x position across the width of the lead image.
        height, width = lead_image.shape
        signal_points = []
        
        for x in range(width):
            # Create a mask for the current x-column and draw the main contour onto it.
            mask = np.zeros((height, width), dtype=np.uint8)
            cv2.drawContours(mask, [main_contour], -1, 255, -1)
            
            # Find y-positions where the contour exists in the current column.
            column = mask[:, x]
            y_positions = np.where(column > 0)[0]
            
            if len(y_positions) > 0:
                # Use the median y-position to get a single, robust signal value for the column.
                # This helps handle the thickness of the ECG trace.
                y_median = np.median(y_positions)
                # Invert y-coordinate as image origins are top-left, but ECG is usually plotted with Y increasing upwards.
                signal_value = (height - y_median) / height
                signal_points.append(signal_value)
            else:
                # If no contour points found in a column, interpolate or use a baseline value.
                if signal_points:
                    signal_points.append(signal_points[-1]) # Use last known value
                else:
                    signal_points.append(0.5)  # Default to baseline (mid-point) if no prior points
        
        # Convert the list of signal points to a numpy array.
        digital_signal = np.array(signal_points)
        # Scale the signal to a typical range, e.g., [-1, 1].
        digital_signal = (digital_signal - 0.5) * 2
        
        # Resample the signal to the desired sampling rate.
        # This ensures consistency for analysis models.
        if len(digital_signal) > 0:
            target_length = int(len(digital_signal) * sampling_rate / 500) # Assuming original effective rate is 500
            digital_signal = signal.resample(digital_signal, target_length)
        
        return digital_signal

class ECGAnalysisEngine:
    """
    Advanced ECG analysis engine combining deep learning models and clinical feature extraction.
    """
    
    def __init__(self):
        self.models = {}
        self.feature_extractors = {}
        # List of emergency cardiac conditions this system is designed to detect.
        self.emergency_conditions = [
            'STEMI', 'NSTEMI', 'Sustained_VT', 'VF', 'Complete_Heart_Block',
            'Unstable_AFib', 'Torsades', 'Cardiogenic_Shock'
        ]
        
    def build_hybrid_model(self) -> Model:
        """
        Builds a hybrid deep learning model that takes both image data (from scanned ECGs)
        and digital signal data as input for comprehensive analysis.
        """
        # Image branch: Processes image features, potentially from scanned ECGs.
        # Input shape for images (e.g., resized for ResNet50).
        # Note: For a true 12-lead analysis, the image input would need to accommodate
        # all leads, possibly as a larger multi-channel image or an array of single-lead images.
        image_input = Input(shape=(224, 224, 3), name='image_input')
        
        # Use ResNet50 as a convolutional backbone for image feature extraction.
        # 'include_top=False' means we don't include the final classification layers of ResNet50.
        base_model = ResNet50(weights='imagenet', include_top=False, 
                             input_tensor=image_input)
        
        # Freeze initial layers of the ResNet50 to use pre-trained features without modifying them.
        for layer in base_model.layers[:-4]: # Unfreeze last 4 layers for fine-tuning
            layer.trainable = False
        
        # Global Average Pooling reduces spatial dimensions to a single feature vector per image.
        x_img = GlobalAveragePooling2D()(base_model.output)
        # Fully connected layers for image features.
        x_img = Dense(256, activation='relu')(x_img)
        x_img = Dropout(0.3)(x_img)
        
        # Signal branch: Processes time-series ECG digital signals.
        # Input shape for signals (e.g., 10 seconds at 500 Hz).
        # Note: For a 12-lead analysis, this input should be `(5000, 12)` if all leads are combined
        # into a single array, or the model would need 12 separate signal inputs, potentially
        # processing them in parallel and concatenating their features.
        signal_input = Input(shape=(5000, 1), name='signal_input')
        
        # 1D Convolutional layers for feature extraction from time-series data.
        x_sig = Conv1D(64, 15, activation='relu')(signal_input)
        x_sig = BatchNormalization()(x_sig)
        x_sig = MaxPooling2D(pool_size=2)(x_sig)
        
        x_sig = Conv1D(128, 15, activation='relu')(x_sig)
        x_sig = BatchNormalization()(x_sig)
        x_sig = MaxPooling2D(pool_size=2)(x_sig)
        
        # Bidirectional LSTMs for capturing temporal dependencies in the ECG signal.
        x_sig = Bidirectional(LSTM(128, return_sequences=True))(x_sig)
        x_sig = Bidirectional(LSTM(64))(x_sig)
        x_sig = Dropout(0.3)(x_sig)
        
        # Combine features from both image and signal branches.
        combined = Concatenate()([x_img, x_sig])
        
        # Final classification layers for combined features.
        x = Dense(512, activation='relu')(combined)
        x = Dropout(0.4)(x)
        x = Dense(256, activation='relu')(x)
        x = Dropout(0.3)(x)
        
        # Multi-task outputs:
        # 1. Emergency detection (binary classification: emergency/non-emergency).
        emergency_output = Dense(1, activation='sigmoid', name='emergency')(x)
        # 2. Cardiac condition classification (multi-class: 15 conditions).
        condition_output = Dense(15, activation='softmax', name='condition')(x)
        # 3. Severity score prediction (regression).
        severity_output = Dense(1, activation='sigmoid', name='severity')(x) # Sigmoid for a score between 0 and 1
        
        # Create the Keras Model with multiple inputs and outputs.
        model = Model(inputs=[image_input, signal_input], 
                     outputs=[emergency_output, condition_output, severity_output])
        
        # Compile the model with Adam optimizer and specific loss functions and weights for each output.
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss={
                'emergency': 'binary_crossentropy',
                'condition': 'sparse_categorical_crossentropy', # Use sparse if labels are integers
                'severity': 'mse'
            },
            loss_weights={
                'emergency': 2.0,  # Prioritize emergency detection
                'condition': 1.0,
                'severity': 0.5
            },
            metrics={
                'emergency': ['accuracy', 'precision', 'recall'],
                'condition': ['accuracy'],
                'severity': ['mae']
            }
        )
        
        return model
    
    def extract_clinical_features(self, signal: np.ndarray, 
                                 sampling_rate: int = 500) -> Dict:
        """
        Extracts comprehensive clinical features from a digital ECG signal using NeuroKit2.
        """
        try:
            # Clean the ECG signal (e.g., remove baseline wander, high-frequency noise).
            ecg_cleaned = nk.ecg_clean(signal, sampling_rate=sampling_rate)
            
            # Detect R-peaks, which are crucial for heart rate and HRV analysis.
            peaks, _ = nk.ecg_peaks(ecg_cleaned, sampling_rate=sampling_rate)
            
            # Calculate Heart Rate Variability (HRV) parameters.
            hrv = nk.hrv(peaks, sampling_rate=sampling_rate, show=False)
            
            # Perform ECG delineation to identify P, QRS, and T wave onsets/offsets.
            waves = nk.ecg_delineate(ecg_cleaned, peaks, sampling_rate=sampling_rate)
            
            # Calculate various standard ECG intervals and features.
            features = {
                'heart_rate': self._calculate_heart_rate(peaks['ECG_R_Peaks'], sampling_rate),
                'rr_intervals': self._get_rr_intervals(peaks['ECG_R_Peaks'], sampling_rate),
                'pr_interval': self._calculate_pr_interval(waves, sampling_rate),
                'qrs_duration': self._calculate_qrs_duration(waves, sampling_rate),
                'qt_interval': self._calculate_qt_interval(waves, sampling_rate),
                'st_elevation': self._measure_st_elevation(ecg_cleaned, waves, sampling_rate),
                'hrv_features': hrv.to_dict('records')[0] if not hrv.empty else {},
                'signal_quality': self._assess_signal_quality(ecg_cleaned)
            }
            
            return features
            
        except Exception as e:
            logger.error(f"Feature extraction failed: {e}")
            return self._get_default_features()
    
    def _calculate_heart_rate(self, r_peaks: np.ndarray, sampling_rate: int) -> float:
        """Calculates heart rate in BPM from detected R-peaks."""
        if len(r_peaks) < 2:
            return 0.0
        
        # Calculate time difference between consecutive R-peaks.
        rr_intervals = np.diff(r_peaks) / sampling_rate
        # Heart rate is 60 divided by the average RR interval in seconds.
        heart_rate = 60 / np.mean(rr_intervals)
        return float(heart_rate)
    
    def _get_rr_intervals(self, r_peaks: np.ndarray, sampling_rate: int) -> List[float]:
        """Gets RR intervals in milliseconds."""
        if len(r_peaks) < 2:
            return []
        
        # Calculate RR intervals in samples, convert to seconds, then to milliseconds.
        rr_intervals = np.diff(r_peaks) / sampling_rate * 1000
        return rr_intervals.tolist()
    
    def _calculate_pr_interval(self, waves: dict, sampling_rate: int) -> float:
        """Calculates the PR interval in milliseconds."""
        try:
            p_onsets = waves.get('ECG_P_Onsets', [])
            qrs_onsets = waves.get('ECG_Q_Peaks', []) # Or ECG_QRS_Onsets if available
            
            if len(p_onsets) > 0 and len(qrs_onsets) > 0:
                # Calculate average PR interval from corresponding P onset and QRS onset.
                pr_samples = np.nanmean([qrs_onsets[i] - p_onsets[i] for i in range(min(len(p_onsets), len(qrs_onsets)))
                                    if not np.isnan(p_onsets[i]) and not np.isnan(qrs_onsets[i])])
                if not np.isnan(pr_samples):
                    return float(pr_samples / sampling_rate * 1000)  # Convert to ms
        except Exception as e:
            logger.debug(f"Error calculating PR interval: {e}")
        return 0.0
    
    def _calculate_qrs_duration(self, waves: dict, sampling_rate: int) -> float:
        """Calculates the QRS duration in milliseconds."""
        try:
            qrs_onsets = waves.get('ECG_Q_Peaks', []) # Or ECG_QRS_Onsets
            qrs_offsets = waves.get('ECG_S_Peaks', []) # Or ECG_QRS_Offsets
            
            if len(qrs_onsets) > 0 and len(qrs_offsets) > 0:
                # Calculate average QRS duration from corresponding QRS onset and offset.
                qrs_duration = np.nanmean([qrs_offsets[i] - qrs_onsets[i] for i in range(min(len(qrs_onsets), len(qrs_offsets)))
                                      if not np.isnan(qrs_onsets[i]) and not np.isnan(qrs_offsets[i])])
                if not np.isnan(qrs_duration):
                    return float(qrs_duration / sampling_rate * 1000)  # Convert to ms
        except Exception as e:
            logger.debug(f"Error calculating QRS duration: {e}")
        return 0.0
    
    def _calculate_qt_interval(self, waves: dict, sampling_rate: int) -> float:
        """Calculates the QT interval in milliseconds."""
        try:
            qrs_onsets = waves.get('ECG_Q_Peaks', []) # Or ECG_QRS_Onsets
            t_offsets = waves.get('ECG_T_Offsets', [])
            
            if len(qrs_onsets) > 0 and len(t_offsets) > 0:
                # Calculate average QT interval from corresponding QRS onset and T offset.
                qt_interval = np.nanmean([t_offsets[i] - qrs_onsets[i] for i in range(min(len(qrs_onsets), len(t_offsets)))
                                     if not np.isnan(qrs_onsets[i]) and not np.isnan(t_offsets[i])])
                if not np.isnan(qt_interval):
                    return float(qt_interval / sampling_rate * 1000)  # Convert to ms
        except Exception as e:
            logger.debug(f"Error calculating QT interval: {e}")
        return 0.0
    
    def _measure_st_elevation(self, signal: np.ndarray, waves: dict, 
                             sampling_rate: int) -> float:
        """Measures ST segment elevation (or depression) in millivolts."""
        try:
            r_peaks = waves.get('ECG_R_Peaks', [])
            if len(r_peaks) == 0:
                return 0.0
            
            st_elevations = []
            for r_peak in r_peaks:
                if not np.isnan(r_peak):
                    # ST segment is typically measured at J-point (end of QRS) or 60-80ms after R peak.
                    # Using a point 80ms after R-peak as an approximation for ST segment.
                    st_point_idx = int(r_peak + 0.08 * sampling_rate)
                    
                    # Baseline for ST measurement is typically at the PR segment.
                    # Approximated as 50ms before R-peak.
                    baseline_point_idx = int(r_peak - 0.05 * sampling_rate)
                    
                    if 0 <= baseline_point_idx < len(signal) and 0 <= st_point_idx < len(signal):
                        # ST elevation is the difference between the ST segment amplitude and the baseline amplitude.
                        st_elevation = signal[st_point_idx] - signal[baseline_point_idx]
                        st_elevations.append(st_elevation)
            
            return float(np.mean(st_elevations)) if st_elevations else 0.0
        except Exception as e:
            logger.debug(f"Error measuring ST elevation: {e}")
            return 0.0
    
    def _assess_signal_quality(self, signal: np.ndarray) -> float:
        """Assesses signal quality index (0-1) based on Signal-to-Noise Ratio (SNR)."""
        try:
            # Signal power: Variance of the signal itself.
            signal_power = np.var(signal)
            # Noise power: Approximated by the variance of the high-frequency components (e.g., difference).
            noise_power = np.var(np.diff(signal))
            
            if noise_power > 1e-9: # Avoid division by zero
                snr = signal_power / noise_power
                # Normalize SNR to a quality score between 0 and 1.
                # A simple heuristic: cap at 1.0, scale by a factor.
                quality = min(1.0, snr / 100.0)
            else:
                quality = 1.0 # Assume perfect quality if no discernible noise
            
            return float(quality)
        except Exception as e:
            logger.debug(f"Error assessing signal quality: {e}")
            return 0.0
    
    def _get_default_features(self) -> Dict:
        """Returns a dictionary of default (zero/empty) features when extraction fails."""
        return {
            'heart_rate': 0.0,
            'rr_intervals': [],
            'pr_interval': 0.0,
            'qrs_duration': 0.0,
            'qt_interval': 0.0,
            'st_elevation': 0.0,
            'hrv_features': {},
            'signal_quality': 0.0
        }

class ECGScannerDevice:
    """
    Main ECG Scanner Device class, integrating image processing, signal analysis,
    and a multi-threaded processing pipeline.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        self.image_processor = ECGImageProcessor()
        self.analysis_engine = ECGAnalysisEngine()
        self.model = None # The hybrid deep learning model
        self.processing_queue = queue.Queue() # Queue for incoming ECG data (image paths or digital signals)
        self.results_queue = queue.Queue()    # Queue for completed analysis results
        self.is_running = False             # Flag to control the processing thread
        self.processing_thread: Optional[threading.Thread] = None # Reference to the processing thread
        
        # Device operational settings
        self.settings = {
            'sampling_rate': 500, # Hz
            'lead_duration': 10,  # seconds per lead for analysis
            'emergency_threshold': 0.8, # Probability threshold for flagging emergency
            'confidence_threshold': 0.7, # Minimum confidence for condition diagnosis
            'auto_hospitalization_threshold': 0.85 # Higher threshold for automatic hospitalization recommendation
        }
        
        # Initialize or load the deep learning model.
        if model_path and Path(model_path).exists():
            self.load_model(model_path)
        else:
            logger.info("No model loaded - building default hybrid model (untrained).")
            self.model = self.analysis_engine.build_hybrid_model()
    
    def load_model(self, model_path: str):
        """Loads a pre-trained Keras model from the specified path."""
        try:
            self.model = tf.keras.models.load_model(model_path)
            logger.info(f"Model loaded successfully from {model_path}")
        except Exception as e:
            logger.error(f"Failed to load model from {model_path}: {e}. Building default model instead.")
            self.model = self.analysis_engine.build_hybrid_model() # Fallback to building a new model

    def train_model(self, 
                    train_images: Optional[np.ndarray] = None, 
                    train_signals: Optional[np.ndarray] = None, 
                    train_emergency_labels: Optional[np.ndarray] = None,
                    train_condition_labels: Optional[np.ndarray] = None,
                    train_severity_labels: Optional[np.ndarray] = None,
                    epochs: int = 10, 
                    batch_size: int = 32, 
                    validation_split: float = 0.2,
                    model_save_path: str = "trained_ecg_model.h5"):
        """
        Trains the hybrid deep learning model using provided ECG data.

        Args:
            train_images (np.ndarray, optional): NumPy array of preprocessed ECG images for training.
                Shape should be (num_samples, 224, 224, 3). Defaults to None.
            train_signals (np.ndarray, optional): NumPy array of preprocessed digital ECG signals for training.
                Shape should be (num_samples, 5000, 1). Defaults to None.
            train_emergency_labels (np.ndarray, optional): Binary labels for emergency detection.
                Shape should be (num_samples,). Defaults to None.
            train_condition_labels (np.ndarray, optional): Integer labels for cardiac conditions (0-14).
                Shape should be (num_samples,). Defaults to None.
            train_severity_labels (np.ndarray, optional): Float labels for severity score (0-1).
                Shape should be (num_samples,). Defaults to None.
            epochs (int): Number of training epochs. Defaults to 10.
            batch_size (int): Batch size for training. Defaults to 32.
            validation_split (float): Fraction of the training data to be used as validation data. Defaults to 0.2.
            model_save_path (str): Path to save the trained model. Defaults to "trained_ecg_model.h5".
        """
        logger.info("Starting model training...")

        # Prepare inputs and outputs for the model based on available data
        model_inputs = {}
        model_outputs = {}

        if train_images is not None:
            model_inputs['image_input'] = train_images
            logger.info(f"Training with {train_images.shape[0]} image samples.")
        else:
            logger.warning("No image data provided for training. Image branch of model will not be effectively trained.")
            # Create dummy image input if only signal data is provided, to satisfy model input
            # For pure signal training, one might rebuild the model without the image branch or use a dummy.
            # Here, we'll create a dummy input to prevent crashes if the model expects it.
            if train_signals is not None: # only add dummy if there are signals to prevent empty inputs
                model_inputs['image_input'] = np.zeros((train_signals.shape[0], 224, 224, 3), dtype=np.float32)


        if train_signals is not None:
            model_inputs['signal_input'] = train_signals
            logger.info(f"Training with {train_signals.shape[0]} signal samples.")
        else:
            logger.warning("No signal data provided for training. Signal branch of model will not be effectively trained.")
            if train_images is not None: # only add dummy if there are images
                model_inputs['signal_input'] = np.zeros((train_images.shape[0], 5000, 1), dtype=np.float32)


        if not model_inputs:
            logger.error("No valid training input data (images or signals) provided. Cannot train model.")
            return

        # Prepare labels for the model outputs
        if train_emergency_labels is not None:
            model_outputs['emergency'] = train_emergency_labels
        else:
            logger.warning("No emergency labels provided for training. Emergency branch will not be trained.")

        if train_condition_labels is not None:
            model_outputs['condition'] = train_condition_labels
        else:
            logger.warning("No condition labels provided for training. Condition branch will not be trained.")

        if train_severity_labels is not None:
            model_outputs['severity'] = train_severity_labels
        else:
            logger.warning("No severity labels provided for training. Severity branch will not be trained.")

        if not model_outputs:
            logger.error("No valid training output labels provided. Cannot train model.")
            return
            
        # Ensure that input and output data counts match
        num_samples = len(list(model_inputs.values())[0])
        for key, value in model_inputs.items():
            if len(value) != num_samples:
                logger.error(f"Mismatch in number of samples for input '{key}': {len(value)} vs {num_samples}")
                return
        for key, value in model_outputs.items():
            if len(value) != num_samples:
                logger.error(f"Mismatch in number of samples for output '{key}': {len(value)} vs {num_samples}")
                return

        # If model is not built yet, build it
        if self.model is None:
            self.model = self.analysis_engine.build_hybrid_model()

        # Define callbacks
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
            ModelCheckpoint(filepath=model_save_path, save_best_only=True, monitor='val_loss', mode='min')
        ]

        try:
            logger.info(f"Training model for {epochs} epochs with batch size {batch_size}...")
            history = self.model.fit(
                x=model_inputs,
                y=model_outputs,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=validation_split,
                callbacks=callbacks,
                verbose=1
            )
            logger.info("Model training completed.")

            # Load the best weights saved by ModelCheckpoint
            if Path(model_save_path).exists():
                self.load_model(model_save_path)
                logger.info(f"Best trained model weights loaded from {model_save_path}")
            else:
                logger.warning("Model checkpoint was not created. Using final epoch weights.")

            return history

        except Exception as e:
            logger.critical(f"Error during model training: {e}", exc_info=True)
            print(f"Error during model training: {e}. Please check logs.")
            return None
    
    def scan_paper_ecg(self, image_path: str) -> Dict:
        """
        Executes the complete pipeline for scanning a paper ECG image,
        digitizing it, and performing analysis.
        """
        try:
            logger.info(f"Initiating processing for paper ECG image: {image_path}")
            
            # Step 1: Preprocess the input image.
            processed_image = self.image_processor.preprocess_image(image_path)
            
            # Step 2: Extract individual ECG leads from the processed image.
            # NOTE: For a truly comprehensive analysis and to fully utilize a 12-lead capable model,
            # ALL extracted leads should be passed for feature extraction and potentially to the model.
            # Current model architecture has a single signal input (5000,1), which implies a single lead.
            # The 'leads' variable contains all segmented lead images.
            leads = self.image_processor.extract_ecg_grid(processed_image)
            
            # Step 3: Digitize each extracted lead into a numerical signal.
            digital_signals_all_leads = []
            for i, lead_img in enumerate(leads):
                signal_data = self.image_processor.digitize_ecg_signal(
                    lead_img, self.settings['sampling_rate'])
                digital_signals_all_leads.append(signal_data)
                logger.info(f"Lead {i+1} digitized: {len(signal_data)} samples")
            
            # For the current single-signal input model, we'll use the rhythm strip (last lead)
            # as the primary input for direct signal analysis.
            # In a full 12-lead system, you would:
            # 1. Adapt the deep learning model input to accept multiple leads (e.g., (N_samples, 12) or 12 separate inputs).
            # 2. Extract clinical features from ALL leads and potentially aggregate them or feed them lead-wise.
            main_signal_for_model = digital_signals_all_leads[-1] if digital_signals_all_leads else np.array([])
            
            if len(main_signal_for_model) == 0:
                logger.error("No discernible signal extracted from the image.")
                return self._get_error_result("No signal extracted from image")
            
            # Step 4: Perform core analysis on the main digital signal.
            # The analyze_signal method will extract clinical features from main_signal_for_model
            # and potentially use pre-extracted features from other leads if the model is designed for it.
            analysis_result = self.analyze_signal(main_signal_for_model, source='paper_ecg', all_leads_data=digital_signals_all_leads)
            
            # Add image-specific metadata to the result.
            analysis_result['image_path'] = image_path
            analysis_result['leads_extracted_count'] = len(digital_signals_all_leads) # Count of leads extracted
            analysis_result['timestamp'] = datetime.now().isoformat()
            
            logger.info(f"Paper ECG processing complete for {image_path}. Condition: {analysis_result['condition']}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"Critical error processing paper ECG {image_path}: {e}", exc_info=True)
            return self._get_error_result(f"Error processing paper ECG: {e}")
    
    def analyze_digital_signal(self, signal: np.ndarray, all_leads_data: Optional[List[np.ndarray]] = None) -> Dict:
        """
        Analyzes a pre-digitized ECG signal directly.
        """
        logger.info(f"Analyzing digital ECG signal of length {len(signal)}. Source: digital input.")
        return self.analyze_signal(signal, source='digital', all_leads_data=all_leads_data)
    
    def analyze_signal(self, main_signal: np.ndarray, source: str = 'unknown', 
                       all_leads_data: Optional[List[np.ndarray]] = None) -> Dict:
        """
        Core signal analysis function that extracts clinical features and uses the
        deep learning model (or a fallback) for prediction.

        Args:
            main_signal (np.ndarray): The primary ECG signal (e.g., rhythm strip) for model input.
            source (str): Source of the signal (e.g., 'digital', 'paper_ecg', 'simulated_device').
            all_leads_data (Optional[List[np.ndarray]]): List of all digitized leads, if available.
                                                        Used for more comprehensive feature extraction.
        """
        try:
            # Step 1: Extract comprehensive clinical features using medical signal processing libraries.
            # If all_leads_data is provided, we can extract features from multiple leads
            # and potentially combine them for a more robust clinical assessment.
            # For this example, features are extracted from the main_signal.
            features = self.analysis_engine.extract_clinical_features(
                main_signal, self.settings['sampling_rate'])
            
            # Step 2: Prepare the signal for model input (resampling, normalization, reshaping).
            signal_input = self._prepare_signal_for_model(main_signal)
            
            # Create a dummy image input for the hybrid model if no image data is available.
            image_input = np.zeros((1, 224, 224, 3), dtype=np.float32) # Batch size 1, RGB image
            
            emergency_prob = 0.0
            condition_probs = np.zeros(15) # Assuming 15 conditions
            severity_score = 0.0
            
            # Step 3: Perform model prediction or fallback analysis.
            if self.model:
                predictions = self.model.predict([image_input, signal_input], verbose=0)
                emergency_prob = float(predictions[0][0])
                condition_probs = predictions[1][0]
                severity_score = float(predictions[2][0])
                logger.info(f"Model prediction: Emergency Prob={emergency_prob:.2f}")
            else:
                # Fallback to rule-based analysis if the model is not loaded/available.
                emergency_prob, condition_probs, severity_score = self._fallback_analysis(features)
                logger.warning("Using fallback analysis as no model is loaded.")
            
            # Define the names for the 15 cardiac conditions used in the model.
            condition_names = [
                'Normal', 'STEMI', 'NSTEMI', 'Unstable_Angina', 'Stable_Angina',
                'Atrial_Fibrillation', 'Atrial_Flutter', 'Sustained_VT', 'NSVT', 'VF',
                'Complete_Heart_Block', 'Mobitz_II', 'Mobitz_I', 'Bradycardia', 'Tachycardia'
            ]
            
            # Determine the predicted condition based on the highest probability.
            predicted_condition = condition_names[np.argmax(condition_probs)]
            condition_confidence = float(np.max(condition_probs))
            
            # Step 4: Clinical decision making based on prediction thresholds.
            is_emergency = emergency_prob > self.settings['emergency_threshold']
            requires_hospitalization = (
                is_emergency and 
                condition_confidence > self.settings['auto_hospitalization_threshold']
            )
            
            # Compile all results into a single dictionary.
            result = {
                'condition': predicted_condition,
                'emergency_probability': emergency_prob,
                'condition_confidence': condition_confidence,
                'severity_score': severity_score,
                'is_emergency': is_emergency,
                'requires_hospitalization': requires_hospitalization,
                'clinical_features': features,
                'recommendations': self._generate_recommendations(
                    predicted_condition, emergency_prob, features, requires_hospitalization),
                'source': source,
                'timestamp': datetime.now().isoformat(),
                'device_id': 'ECG_SCANNER_001' # Unique identifier for this device instance
            }
            
            # Step 5: Log critical cases for immediate attention and quality assurance.
            if is_emergency:
                self._log_emergency_case(result)
            
            return result
            
        except Exception as e:
            logger.error(f"Critical error during signal analysis (source: {source}): {e}", exc_info=True)
            return self._get_error_result(f"Error in signal analysis: {e}")
    
    def _prepare_signal_for_model(self, signal: np.ndarray) -> np.ndarray:
        """
        Prepares the digital ECG signal for input to the deep learning model.
        This includes resampling to a fixed length, normalization, and reshaping.
        """
        target_length = self.settings['sampling_rate'] * self.settings['lead_duration'] # e.g., 5000 samples for 10s at 500Hz
        
        if len(signal) == 0:
            return np.zeros((1, target_length, 1), dtype=np.float32) # Return empty array if no signal
        
        # Resample if the signal length does not match the target length.
        if len(signal) != target_length:
            # Use scipy.signal.resample for resampling.
            signal = signal.astype(np.float32) # Ensure float type for resampling
            signal = signal.resample(signal, target_length)
        
        # Normalize the signal to have zero mean and unit variance.
        # This helps models train more effectively. Add a small epsilon to prevent division by zero.
        signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-8)
        
        # Reshape for model input: (batch_size, sequence_length, features)
        # Here, batch_size is 1, sequence_length is target_length, and features is 1 (for single lead).
        return signal.reshape(1, target_length, 1)
    
    def _fallback_analysis(self, features: Dict) -> Tuple[float, np.ndarray, float]:
        """
        Provides a rule-based fallback analysis for cardiac conditions when the
        deep learning model is not available or fails.
        """
        emergency_prob = 0.0
        condition_probs = np.zeros(15) # Initialize all condition probabilities to zero
        severity_score = 0.0
        
        # Retrieve key clinical features.
        hr = features.get('heart_rate', 70) # Default HR to 70 if not found
        st_elevation = features.get('st_elevation', 0)
        qrs_duration = features.get('qrs_duration', 0)
        qt_interval = features.get('qt_interval', 400) # Default QT to 400ms
        pr_interval = features.get('pr_interval', 160) # Default PR to 160ms
        
        # Apply simple rules for emergency detection and condition probability.
        
        # Rule 1: Extreme heart rates (Tachycardia/Bradycardia)
        if hr > 100: # Tachycardia
            emergency_prob += 0.2
            condition_probs[14] = 0.5 # High probability for Tachycardia
            if hr > 150: # Very fast Tachycardia
                emergency_prob += 0.2
                if hr > 200: # Potentially VT/VF
                    emergency_prob += 0.3
                    condition_probs[7] = 0.6 # Sustained VT
                    condition_probs[9] = 0.4 # VF
        elif hr < 60: # Bradycardia
            emergency_prob += 0.2
            condition_probs[13] = 0.5 # High probability for Bradycardia
            if hr < 40: # Severe Bradycardia, possibly heart block
                emergency_prob += 0.3
                condition_probs[10] = 0.5 # Complete Heart Block
        
        # Rule 2: Significant ST segment changes (indicative of ischemia/infarction)
        if st_elevation > 0.2: # Significant ST elevation (e.g., > 0.2 mV)
            emergency_prob += 0.5
            condition_probs[1] = 0.8 # High probability for STEMI
        elif st_elevation < -0.1: # Significant ST depression (e.g., < -0.1 mV)
            emergency_prob += 0.3
            condition_probs[2] = 0.7 # High probability for NSTEMI
        
        # Rule 3: QRS Duration (indicating bundle branch block or ventricular rhythm)
        if qrs_duration > 120: # Prolonged QRS duration (e.g., > 120 ms)
            emergency_prob += 0.1
            # Could indicate Bundle Branch Block (not explicitly in condition list but important)
            
        # Rule 4: Prolonged QT interval (risk of Torsades de Pointes)
        if qt_interval > 450: # Prolonged QT (e.g., > 450 ms in males, > 470 ms in females, simplified for now)
            emergency_prob += 0.3
            # Potentially Torsades
        
        # Rule 5: PR Interval (indicating AV blocks)
        if pr_interval > 200: # Prolonged PR interval
            emergency_prob += 0.1
            condition_probs[12] = 0.4 # Mobitz I / First-degree AV block
        
        # If overall emergency probability is low, and no specific condition highly probable, lean towards Normal
        if emergency_prob < 0.5 and np.sum(condition_probs) < 0.5:
            condition_probs[0] = 1.0 - np.sum(condition_probs) # Assign remaining prob to Normal

        # Rule 6: Very low signal quality might indicate issues, but not an emergency itself
        if features.get('signal_quality', 1.0) < 0.5:
            logger.warning("Fallback analysis: Very low signal quality. Results may be unreliable.")
            emergency_prob = max(emergency_prob, 0.1) # Introduce some uncertainty due to poor quality

        # Severity score: A simple combination of emergency probability and deviation from normal HR.
        # Max out at 1.0.
        severity_score = min(1.0, emergency_prob + (abs(hr - 75) / 100) + (abs(st_elevation) * 2)) # Incorporate ST elevation
        
        # Normalize condition probabilities.
        if np.sum(condition_probs) > 0:
            condition_probs = condition_probs / np.sum(condition_probs) # Normalize to sum to 1
        else:
            condition_probs[0] = 1.0 # Default to normal if no other probabilities
        
        return emergency_prob, condition_probs, severity_score
    
    def _generate_recommendations(self, condition: str, emergency_prob: float, 
                                features: Dict, requires_hospitalization: bool) -> List[str]:
        """
        Generates a list of clinical recommendations based on the analysis result.
        Recommendations are tiered by urgency and specificity.
        """
        recommendations = []
        
        # Tier 1: Immediate Life-Threatening Concerns
        if requires_hospitalization and emergency_prob >= self.settings['auto_hospitalization_threshold']:
            recommendations.append("üö® CRITICAL: IMMEDIATE HOSPITALIZATION REQUIRED")
            recommendations.append("CALL EMERGENCY SERVICES (e.g., 911/112) IMMEDIATELY.")
            recommendations.append("Initiate Advanced Cardiovascular Life Support (ACLS) protocols if trained.")
        elif emergency_prob >= self.settings['emergency_threshold']:
            recommendations.append("‚ö†Ô∏è URGENT: PROMPT MEDICAL EVALUATION NEEDED")
            recommendations.append("Seek emergency medical attention without delay (e.g., nearest ER).")
        
        # Tier 2: Condition-Specific Interventions/Recommendations
        if 'STEMI' in condition:
            recommendations.extend([
                "Action: Activate Cardiac Catheterization Lab (STEMI Alert Protocol).",
                "Action: Administer Aspirin (162-325 mg chewed) and P2Y12 inhibitor (e.g., Clopidogrel) if not contraindicated.",
                "Action: Consider Nitroglycerin (sublingual) if no contraindications (e.g., hypotension, sildenafil use).",
                "Monitor: Closely monitor for arrhythmias (e.g., VT/VF) and signs of heart failure/shock.",
                "Referral: Urgent cardiology consultation."
            ])
        elif 'NSTEMI' in condition or 'Unstable_Angina' in condition:
            recommendations.extend([
                "Action: Administer Aspirin and P2Y12 inhibitor.",
                "Action: Consider Nitroglycerin (sublingual) for chest pain relief.",
                "Action: Consider beta-blockers if no contraindications.",
                "Monitor: Serial cardiac enzymes and repeat ECGs.",
                "Referral: Cardiology consultation for risk stratification and potential angiography."
            ])
        elif 'Atrial_Fibrillation' in condition or 'Atrial_Flutter' in condition:
            recommendations.extend([
                "Assess: Hemodynamic stability (if unstable, urgent cardioversion).",
                "Action: Rate control (e.g., beta-blockers, calcium channel blockers) or rhythm control strategies.",
                "Action: Evaluate stroke risk (CHA2DS2-VASc score) and consider anticoagulation based on risk."
            ])
        elif 'Sustained_VT' in condition or 'VF' in condition:
            recommendations.extend([
                "Action: If pulseless, immediate defibrillation (CPR if no defibrillator immediately available).",
                "Action: If stable VT, consider antiarrhythmic drugs (e.g., Amiodarone, Procainamide).",
                "Action: Check electrolyte levels (Potassium, Magnesium) and correct abnormalities.",
                "Referral: Urgent electrophysiology consultation."
            ])
        elif 'Complete_Heart_Block' in condition or 'Mobitz_II' in condition:
            recommendations.extend([
                "Assess: Patient's symptoms (syncope, dizziness, fatigue).",
                "Action: Prepare for temporary transcutaneous pacing if symptomatic bradycardia.",
                "Action: Review medications that may exacerbate bradycardia (e.g., beta-blockers, calcium channel blockers).",
                "Referral: Urgent cardiology/electrophysiology consultation for permanent pacemaker consideration."
            ])
        elif 'Bradycardia' in condition and not 'Block' in condition: # Symptomatic Bradycardia
            if features.get('heart_rate', 0) < 50:
                recommendations.extend([
                    "Assess: Patient's symptoms (hypotension, altered mental status, chest pain).",
                    "Action: Consider Atropine (IV) if symptomatic.",
                    "Action: Prepare for transcutaneous pacing if Atropine ineffective.",
                    "Review: Medications that might contribute to bradycardia."
                ])
        elif 'Tachycardia' in condition and not ('VT' in condition or 'AFib' in condition): # SVT/Sinus Tachycardia
            if features.get('heart_rate', 0) > 120:
                 recommendations.extend([
                    "Assess: Hemodynamic stability.",
                    "Action: If stable and narrow complex, consider vagal maneuvers (e.g., Valsalva).",
                    "Action: If vagal maneuvers ineffective, consider Adenosine (IV) for SVT.",
                    "Review: Underlying causes (e.g., fever, dehydration, anxiety, hyperthyroidism)."
                ])
        
        # Tier 3: General Advice & Signal Quality Warnings
        if features.get('signal_quality', 1.0) < 0.7:
            recommendations.append("‚ö†Ô∏è Signal quality suboptimal - consider repeating the recording for clearer results. Ensure good lead contact.")
        
        if not recommendations: # If no specific urgent recommendations, provide general advice
            recommendations.append("Conclusion: ECG appears within normal limits for the analyzed lead, or findings are non-specific.")
            recommendations.append("Recommendation: Routine follow-up with a healthcare provider is advised for ongoing monitoring.")
            recommendations.append("Disclaimer: This is an automated analysis. Always consult with a qualified medical professional for diagnosis and treatment.")
        else:
            # Add general disclaimer to all recommendations
            recommendations.append("--- IMPORTANT DISCLAIMER ---")
            recommendations.append("This is an automated analysis and is not a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a medical condition.")
            
        return recommendations
    
    def _log_emergency_case(self, result: Dict):
        """
        Logs detected emergency cases to the system log and prints a critical alert to console.
        In a production system, this would trigger actual alerts to medical staff.
        """
        emergency_log = {
            'timestamp': result['timestamp'],
            'condition': result['condition'],
            'emergency_probability': result['emergency_probability'],
            'confidence': result['condition_confidence'],
            'heart_rate': result['clinical_features'].get('heart_rate', 0),
            'st_elevation': result['clinical_features'].get('st_elevation', 0),
            'device_id': result['device_id']
        }
        
        logger.critical(f"EMERGENCY CASE DETECTED: {json.dumps(emergency_log)}")
        
        # Display a prominent alert in the console.
        print(f"\n{'='*50}")
        print(f"üö®üö® CRITICAL ALERT DETECTED üö®üö®")
        print(f"Condition: {result['condition']}")
        print(f"Emergency Probability: {result['emergency_probability']:.1%}")
        print(f"Requires Hospitalization: {'YES' if result['requires_hospitalization'] else 'NO'}")
        print(f"Timestamp: {result['timestamp']}")
        print(f"RECOMMENDATIONS:\n- " + "\n- ".join(result['recommendations']))
        print(f"{'='*50}\n")
    
    def _get_error_result(self, error_message: str) -> Dict:
        """
        Returns a standardized error result dictionary for consistency.
        """
        return {
            'condition': 'ERROR',
            'emergency_probability': 0.0,
            'condition_confidence': 0.0,
            'severity_score': 0.0,
            'is_emergency': False,
            'requires_hospitalization': False,
            'clinical_features': self._get_default_features(),
            'recommendations': [f"Error: {error_message}", "Please check the input data and try again.", "Disclaimer: This is an automated analysis. Always consult with a qualified medical professional for diagnosis and treatment."],
            'source': 'error',
            'timestamp': datetime.now().isoformat(),
            'device_id': 'ECG_SCANNER_001',
            'error_message': error_message
        }

    def start_monitoring(self):
        """
        Starts a background thread to continuously process incoming ECG data.
        This simulates real-time data acquisition and analysis from a hardware device.
        """
        if self.is_running:
            logger.warning("ECG monitoring service is already running.")
            return

        self.is_running = True
        logger.info("Starting ECG monitoring service in background thread.")
        # Create a daemon thread so it terminates automatically when the main program exits.
        self.processing_thread = threading.Thread(target=self._processing_loop, name="ECGProcessorThread")
        self.processing_thread.daemon = True
        self.processing_thread.start()
        logger.info("ECG processing thread initiated.")

    def stop_monitoring(self):
        """
        Stops the background monitoring thread gracefully.
        """
        if not self.is_running:
            logger.warning("ECG monitoring service is not running.")
            return

        self.is_running = False
        logger.info("Stopping ECG monitoring service. Waiting for thread to finish...")
        # Wait for the processing thread to complete any current task and exit.
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=5) # Give it 5 seconds to shut down
            if self.processing_thread.is_alive():
                logger.warning("ECG processing thread did not terminate gracefully within timeout.")
        logger.info("ECG monitoring service stopped.")

    def _processing_loop(self):
        """
        The main loop for the background processing thread.
        It continuously checks the `processing_queue` for new data and analyzes it.
        If no data is in the queue, it simulates hardware data acquisition.
        """
        logger.info("ECG processing loop started.")
        while self.is_running:
            try:
                # Attempt to get an item from the queue with a timeout.
                # This prevents blocking indefinitely if no data is present.
                item = self.processing_queue.get(timeout=0.5) # Wait up to 0.5 seconds
                
                # Process the retrieved item (either image path or digital signal).
                if item['type'] == 'image':
                    logger.info(f"Processing queued image: {item['path']}")
                    result = self.scan_paper_ecg(item['path'])
                elif item['type'] == 'signal':
                    logger.info(f"Processing queued digital signal (length: {len(item['data'])}).")
                    result = self.analyze_digital_signal(item['data'])
                else:
                    result = self._get_error_result("Unknown data type in processing queue.")
                
                # Put the analysis result into the results queue for retrieval by the main application.
                self.results_queue.put(result)
                self.processing_queue.task_done() # Mark the task as done for queue management
                logger.info(f"Analysis complete for {item['type']} data. Result stored.")

            except queue.Empty:
                # If the queue is empty, simulate continuous data acquisition from hardware.
                # This part would be replaced by actual hardware serial communication.
                if HARDWARE_AVAILABLE:
                    # In a real scenario, this would call a method to read from a serial port.
                    self._read_from_hardware() # Simulates reading a new chunk of data
                else:
                    # Generate a dummy ECG signal for simulation if no hardware is available.
                    simulated_signal = self._generate_dummy_signal(self.settings['sampling_rate'],
                                                                   self.settings['lead_duration'])
                    self.process_ecg_data(signal=simulated_signal, source='simulated_device')
                time.sleep(0.1) # Short delay to prevent busy-looping and allow other operations
            except Exception as e:
                logger.error(f"Error encountered in processing loop: {e}", exc_info=True)
                if 'item' in locals():
                    self.processing_queue.task_done() # Ensure task is marked done even on error
                time.sleep(1) # Wait a bit before retrying after an error
        logger.info("ECG processing loop gracefully stopped.")

    def process_ecg_data(self, image_path: Optional[str] = None, signal: Optional[np.ndarray] = None):
        """
        Adds ECG data (either an image path or a digital signal) to the processing queue.
        This method is the primary way to submit data for analysis.
        """
        if image_path:
            # Add an image processing request to the queue.
            if Path(image_path).is_file():
                logger.info(f"Queuing image scan request for: {image_path}")
                self.processing_queue.put({'type': 'image', 'path': image_path})
            else:
                logger.error(f"Image file not found: {image_path}. Not adding to queue.")
        elif signal is not None and len(signal) > 0:
            # Add a digital signal analysis request to the queue.
            logger.info("Queuing digital signal analysis request.")
            self.processing_queue.put({'type': 'signal', 'data': signal})
        else:
            logger.warning("No valid ECG data (image path or signal) provided to process_ecg_data.")

    def get_latest_results(self) -> Optional[Dict]:
        """
        Retrieves the latest available analysis result from the results queue without blocking.
        Returns None if no new results are available.
        """
        try:
            # get_nowait() retrieves an item immediately or raises Empty exception.
            return self.results_queue.get_nowait()
        except queue.Empty:
            return None
        except Exception as e:
            logger.error(f"Error retrieving results from queue: {e}")
            return None

    def _generate_dummy_signal(self, sampling_rate: int, duration: int) -> np.ndarray:
        """
        Generates a synthetic ECG-like signal for simulation and testing purposes.
        This signal includes a baseline rhythm, simulated R-peaks, and some noise.
        """
        num_samples = sampling_rate * duration
        t = np.linspace(0, duration, num_samples, endpoint=False)
        
        # Simulate a primary sine wave component (e.g., P and T waves).
        heart_rate_bpm = 70 + np.random.rand() * 20 # Random heart rate between 70-90 BPM
        frequency = heart_rate_bpm / 60 # Convert BPM to Hz
        
        ecg_signal = 0.2 * np.sin(2 * np.pi * frequency * t)
        
        # Add simulated R-peaks.
        # Determine intervals for R-peaks based on heart rate.
        r_peak_interval_samples = sampling_rate / frequency
        r_peak_indices = np.arange(0, num_samples, r_peak_interval_samples).astype(int)
        
        for idx in r_peak_indices:
            # Ensure the peak doesn't go out of bounds.
            if idx < num_samples - 20: # Make the peak duration around 20 samples
                # Simple triangular peak shape for the QRS complex.
                peak_height = 1.0 + np.random.rand() * 0.5 # Random peak height
                # Rise phase
                ecg_signal[idx:min(idx+10, num_samples)] += np.linspace(0, peak_height, min(10, num_samples - idx))
                # Fall phase
                ecg_signal[min(idx+10, num_samples):min(idx+20, num_samples)] += np.linspace(peak_height, 0, min(10, num_samples - min(idx+10, num_samples)))
        
        # Add random Gaussian noise to simulate signal imperfections.
        ecg_signal += np.random.normal(0, 0.05, num_samples) # Mean 0, standard deviation 0.05
        
        # Simulate some low-frequency baseline wander.
        ecg_signal += 0.05 * np.sin(2 * np.pi * 0.1 * t) # A slow sine wave
        
        return ecg_signal.astype(np.float32) # Ensure signal is float for consistency

    def _read_from_hardware(self):
        """
        Placeholder function for reading actual ECG data from hardware via a serial port.
        This method would be implemented with `pyserial` for real device communication.
        Currently, it simulates by generating dummy data.
        """
        if not HARDWARE_AVAILABLE:
            logger.warning("Hardware interface libraries not available. Cannot read from actual hardware.")
            # If hardware is not available, we don't attempt to read from a non-existent serial port.
            # Instead, let the _processing_loop generate a dummy signal.
            return

        # --- Example of how real hardware reading might look ---
        # try:
        #     # Configure the serial port (e.g., COM port on Windows, /dev/ttyUSB0 on Linux)
        #     # and baud rate to match your ECG hardware device.
        #     ser = serial.Serial('/dev/ttyUSB0', 115200, timeout=1) 
        #     logger.info(f"Attempting to read from serial port: {ser.name}")
        #     
        #     # In a continuous stream, you might read line by line or a fixed number of bytes.
        #     # This example assumes each line from serial contains comma-separated float values.
        #     data_chunk = ser.readline().decode('utf-8').strip()
        #     if data_chunk:
        #         signal_values = [float(x) for x in data_chunk.split(',')]
        #         ecg_data = np.array(signal_values, dtype=np.float32)
        #         self.process_ecg_data(signal=ecg_data, source='hardware_device')
        #         logger.info(f"Read {len(ecg_data)} samples from hardware.")
        #     else:
        #         logger.debug("No data received from hardware in this interval.")
        #         # If no data, still simulate some delay to avoid busy-looping
        #         time.sleep(0.01) 
        #
        # except serial.SerialException as e:
        #     logger.error(f"Serial port error during hardware read: {e}. Please check connection.")
        #     # Important: If a serial error occurs, you might want to stop monitoring or reset serial connection.
        # except ValueError as e:
        #     logger.error(f"Data format error from hardware: {e}. Raw data: {data_chunk}")
        # except Exception as e:
        #     logger.error(f"Unexpected error during hardware read: {e}", exc_info=True)
        # finally:
        #     # In a continuous reading loop, you might not close the serial port here,
        #     # but rather upon `stop_monitoring`.
        #     pass 
        # --- End of example ---
        
        logger.info("Simulating hardware reading: Generating dummy signal.")
        # For demonstration purposes, generate a dummy signal.
        simulated_signal = self._generate_dummy_signal(self.settings['sampling_rate'],
                                                       self.settings['lead_duration'])
        self.process_ecg_data(signal=simulated_signal, source='hardware_device')
        time.sleep(self.settings['lead_duration']) # Simulate the time it takes to acquire a full lead


def main():
    """
    Main function to run the ECG Scanner System.
    Initializes the scanner device and provides a command-line interface for interaction.
    """
    # Create an instance of the ECGScannerDevice.
    # You can specify a path to a trained model file here if you have one, e.g., 'path/to/my_ecg_model.h5'.
    scanner = ECGScannerDevice() 
    
    # Start the continuous background monitoring and processing.
    scanner.start_monitoring()

    print("\n======================================")
    print("  ECG Scanner Device System Initiated")
    print("======================================")
    print("System is now monitoring for incoming ECG data (simulated/queued).")
    print("\nCommands:")
    print("  scan <image_path>  : Process a paper ECG image (e.g., 'scan ecg_image.png')")
    print("  status             : Check for and display the latest analysis result")
    print("  train              : (NEW) Train the model with dummy data (requires data setup)")
    print("  help               : Display this help message")
    print("  quit               : Exit the system")
    print("--------------------------------------\n")

    try:
        # Main command-line interface loop.
        while True:
            command_line = input("ECG-Scanner> ").strip()
            command_parts = command_line.lower().split(' ', 1)
            command = command_parts[0]

            if command == 'quit':
                print("Exiting ECG Scanner System. Goodbye!")
                break
            elif command == 'help':
                print("\nCommands:")
                print("  scan <image_path>  : Process a paper ECG image (e.g., 'scan ecg_image.png')")
                print("  status             : Check for and display the latest analysis result")
                print("  train              : (NEW) Train the model with dummy data (requires data setup)")
                print("  help               : Display this help message")
                print("  quit               : Exit the system")
                print("--------------------------------------\n")
            elif command == 'scan':
                if len(command_parts) > 1:
                    image_path = command_parts[1]
                    # Check if the image file exists before queuing.
                    if Path(image_path).is_file():
                        scanner.process_ecg_data(image_path=image_path)
                        print(f"'{image_path}' added to processing queue. Results will appear under 'status'.")
                    else:
                        print(f"Error: Image file not found at '{image_path}'. Please provide a valid path.")
                else:
                    print("Usage: scan <image_path>")
            elif command == 'status':
                result = scanner.get_latest_results()
                if result:
                    print("\n--- Latest Analysis Result ---")
                    # Pretty print the dictionary result.
                    for key, value in result.items():
                        if isinstance(value, float):
                            print(f"{key}: {value:.2f}")
                        elif isinstance(value, dict):
                            print(f"{key}:")
                            for sub_key, sub_value in value.items():
                                if isinstance(sub_value, float):
                                    print(f"  {sub_key}: {sub_value:.2f}")
                                else:
                                    print(f"  {sub_key}: {sub_value}")
                        elif isinstance(value, list):
                            print(f"{key}:")
                            for item in value:
                                print(f"  - {item}")
                        else:
                            print(f"{key}: {value}")
                    print("-----------------------------\n")
                else:
                    print("No new analysis results available yet. Waiting for processing...")
            elif command == 'train':
                print("Attempting to train model with dummy data...")
                # --- Dummy data generation for demonstration of training ---
                # In a real scenario, you would load your actual dataset here.
                # Example:
                num_training_samples = 100
                dummy_images = np.random.rand(num_training_samples, 224, 224, 3).astype(np.float32)
                dummy_signals = np.random.rand(num_training_samples, 5000, 1).astype(np.float32)
                
                # Dummy labels (0 or 1 for emergency, 0-14 for condition, 0-1 for severity)
                dummy_emergency_labels = np.random.randint(0, 2, num_training_samples)
                dummy_condition_labels = np.random.randint(0, 15, num_training_samples)
                dummy_severity_labels = np.random.rand(num_training_samples)
                
                # Call the train_model method
                history = scanner.train_model(
                    train_images=dummy_images,
                    train_signals=dummy_signals,
                    train_emergency_labels=dummy_emergency_labels,
                    train_condition_labels=dummy_condition_labels,
                    train_severity_labels=dummy_severity_labels,
                    epochs=5, # Reduced for quick demo
                    batch_size=16,
                    model_save_path="trained_ecg_model_demo.h5"
                )
                if history:
                    print("Model training initiated. Check log for details and 'trained_ecg_model_demo.h5' file.")
                    print(f"Training history: {history.history.keys()}")
                else:
                    print("Model training failed. See logs for errors.")
                # --- End of dummy data generation ---
            else:
                print(f"Unknown command: '{command_line}'. Type 'help' for available commands.")
            
            time.sleep(0.1) # Small delay to prevent busy-looping in the main thread

    except KeyboardInterrupt:
        print("\nKeyboardInterrupt detected. Shutting down ECG Scanner System.")
    except Exception as e:
        logger.critical(f"An unexpected error occurred in the main application loop: {e}", exc_info=True)
        print(f"\nAn unrecoverable error occurred: {e}. Please check logs for details.")
    finally:
        # Ensure the background monitoring thread is stopped when the application exits.
        scanner.stop_monitoring()
        logging.shutdown() # Ensure all logs are written

if __name__ == '__main__':
    # Optional: If pytesseract is not in your system PATH, you might need to
    # specify its path manually. Uncomment and modify the line below.
    # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Windows example
    # pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # macOS/Linux example
    main()
